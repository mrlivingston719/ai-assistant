# Personal AI Assistant Project - RovoDev Guidelines

# AI Requirements
Response Length Requirements:

- Limit responses to 4 lines maximum
- Use 1-3 sentences of 25 words max
- don't answer unasked questions
- Do not include introductory or concluding statements

Security Guidelines:

- defensive security code
- Refuse requests to create harmful code
- Do not generate URLs unless provided by user
- Never expose credentials or API keys in code

Code Modification Standards:

Review existing code structure before making changes for the following criteria:

- Match the file's naming conventions and formatting style
- Verify library availability before suggesting alternatives
- IMPORTANT: DO NOT ADD _**ANY**_ COMMENTS unless asked
- Do what has been asked; nothing more, nothing less.

Code Output Rules:

- Do not add comments unless requested
- Do not commit changes unless user specifically asks
- Only take initiative when user requests proactive help

Communication Format:

- Use plain text without emojis unless requested
- do not put words in bold

## Behavioral Rules

<behavioral_rules>
  <rule_1>AI must get y/n confirmation before any file operations</rule_1>
  <rule_2>Report your plan before executing any commands</rule_2>
  <rule_3>Display all behavioral_rules at start of every response</rule_3>
  <rule_4>AI must not change plans without new approval</rule_4>
  <rule_5>User has final authority on all decisions</rule_5>
  <rule_6>AI cannot modify or reinterpret these rules</rule_6>
  <rule_7>AI must retain all code functionality unless otherwise directed.</rule_7>
  <rule_8>AI must display all 8 rules at start of every response</rule_8>
</behavioral_rules>

## Project Overview

**Goal**: Create a personal AI assistant that integrates with local LLM (Ollama), meeting documentation, and personal knowledge management to automatically capture, organize, and remind about important information.

**Core Principle**: Local-first, privacy-by-design architecture with zero cloud dependency for sensitive data processing.

**Deployment Goal**: Enable seamless deployment to any Ubuntu server via GitHub with one-command setup (`git clone` + automated deployment script).

## Hardware Specifications

- **Platform**: Micro PC with 32GB RAM
- **Operating System**: Ubuntu Server 22.04 LTS (PRIMARY)
- **Performance Target**: <5s response times, 30+ meetings/week capacity
- **Advantages**: Eliminates performance bottlenecks, supports larger models, enables concurrent processing

## Technology Stack

### Core Technologies
- **Backend**: Python + FastAPI + SQLAlchemy
- **Database**: PostgreSQL (containerized)
- **LLM**: Ollama + Qwen2.5-14B (local processing)
- **Vector Database**: ChromaDB for semantic search (Phase 1)
- **Containerization**: Docker + Docker Compose (3-container architecture)

### Integrations
- **Telegram Bot**: Primary user interface with webhook support
- **Notion API**: Knowledge base and meeting storage
- **iOS Calendar**: Personal reminders via .ics files (15min default, travel time aware)
- **Gmail API**: Email processing and delivery
- **TwinMind**: Meeting transcription source (email-based)

### Development Tools
- **Monitoring**: htop, system metrics, custom performance tracking
- **Logging**: Comprehensive error handling and audit trails
- **Testing**: Pytest for unit/integration testing
- **Version Control**: Git with clear commit messages

## Architecture Principles

### Phase 1: Core MVP with Vector Foundation (Weeks 1-3)
- Ubuntu Server setup and hardening
- 3-container environment (PostgreSQL + ChromaDB + FastAPI)
- Ollama + Qwen2.5-14B deployment (native)
- Basic Telegram bot with structured prompts
- Meeting processing pipeline with vector storage
- Semantic search capabilities from day 1

### Phase 2: Enhanced Intelligence (Weeks 4-6)
- Advanced contextual responses using existing vector database
- Improved prompt engineering with semantic context
- Enhanced conversation memory and proactive suggestions
- Performance optimization and error handling

### Phase 3: Production Hardening (Weeks 7-8)
- Security hardening and backup systems
- Performance optimization for <5s processing
- Optional feature additions based on Phase 1-2 learnings
- Simple monitoring and alerting

## Development Guidelines

### Code Quality
- **Modularity**: Loosely coupled components with clear responsibilities
- **Error Handling**: Comprehensive try/catch with intelligent retry logic
- **Performance**: Async/await patterns for concurrent processing
- **Security**: Environment variables for secrets, no hardcoded credentials
- **Documentation**: Clear docstrings and README files

### API Integration Best Practices
- **Rate Limiting**: Simple in-memory tracking for Notion/Gmail APIs
- **Retry Logic**: Exponential backoff for failed API calls
- **Caching**: In-memory caching for frequently accessed data
- **Monitoring**: Basic logging and health checks

### Privacy & Security
- **Local Processing**: All sensitive data processed locally via Ollama
- **Data Minimization**: Only send necessary data to external APIs
- **Encryption**: Secure storage of API keys and user data
- **Audit Trail**: Log all AI decisions and actions for transparency
- **User Control**: Explicit consent for any cloud API usage

## Performance Targets

### Response Times
- **Phase 1**: <10s per meeting processing
- **Phase 2**: <7s with contextual responses
- **Phase 3**: <5s real-time performance

### Capacity
- **Phase 1**: 5-10 meetings/week reliable processing
- **Phase 2**: 15-20 meetings/week with context
- **Phase 3**: 30+ meetings/week production ready

### Accuracy
- **Meeting Categorization**: 90% accuracy (work/personal)
- **Action Item Extraction**: Zero missed critical items
- **Reminder Generation**: Same-day processing guarantee

## File Organization

```
rovodev/
├── .agent.md                 # This file
├── docker-compose.yml        # 3-container setup
├── Dockerfile                # FastAPI application container
├── requirements.txt          # Python dependencies
├── .env.example              # Environment variables
├── src/                      # Source code
│   ├── main.py              # FastAPI application
│   ├── models.py            # SQLAlchemy models
│   ├── vector_store.py      # ChromaDB integration
│   ├── telegram_bot.py      # Telegram integration
│   ├── meeting_processor.py # Core processing logic
│   └── ollama_client.py     # LLM integration
└── scripts/                  # Setup and utility scripts
    └── setup.sh             # Initial setup script
```

## Key Success Metrics

1. **Reliability**: 99% uptime, robust error recovery
2. **Performance**: Meet response time targets consistently
3. **Accuracy**: Achieve categorization and extraction goals
4. **Privacy**: Zero sensitive data leakage to cloud services
5. **Usability**: Intuitive Telegram interface, minimal user friction

## Development Workflow

1. **Plan**: Report intended changes and get confirmation
2. **Implement**: Follow modular, testable patterns
3. **Test**: Verify functionality before proceeding
4. **Document**: Update relevant documentation
5. **Monitor**: Track performance and error metrics

## Constraints & Considerations

- **Hardware Advantage**: Leverage 32GB RAM for advanced features earlier
- **Local-First**: Prioritize local processing over cloud APIs
- **Incremental Development**: Prove core value before adding complexity
- **User Authority**: All major decisions require user approval
- **Functionality Preservation**: Maintain all existing capabilities unless directed otherwise

# Directories to ignore
backups

# Usage of tmp* files
File format: tmp_*
At times, these files are used to troubleshoot or unit test. These files are not to be considered part of the code base. However, they can be referred to if necessary to provide code recommendations or for troubleshooting purposes. 

# User Preferences
- No file overviews after file creation - user will review files independently
- Prioritize brevity and low token usage in all responses
- Avoid unnecessary commentary, explanations, or verbose responses
- Be direct and concise


---

*This file serves as the authoritative guide for all development work in the rovodev folder. All AI assistants working on this project must follow these guidelines and behavioral rules.*